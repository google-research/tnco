{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Tensor Network Contraction Optimization and Sampling with `tnco` \n",
    "\n",
    "This notebook demonstrates how to use the `tnco` library to optimize the contraction order of tensor networks and perform efficient circuit sampling. We cover quantum circuits (Cirq and Qiskit), arbitrary tensor networks, and advanced sampling techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acf69faa-7599-45f4-bf1c-b24902d51b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cirq\n",
    "import qiskit\n",
    "import pickle\n",
    "import numpy as np\n",
    "import quimb.tensor as qt\n",
    "import more_itertools as mit\n",
    "from random import Random\n",
    "from qiskit.circuit.random import random_circuit as qiskit_random_circuit\n",
    "from tnco.app import Optimizer, Tensor, TensorNetwork\n",
    "from tnco.app.circuit import Sampler\n",
    "import tnco.utils.tn as tn_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2da4a9e-e1cb-4083-81e5-bf3fc13cb898",
   "metadata": {},
   "source": [
    "## 1. Initializing the Optimizer\n",
    "\n",
    "The `Optimizer` class is the main entry point for finding efficient contraction paths. It can be configured with different optimization methods and constraints.\n",
    "\n",
    "- **Method**: The default optimization method is simulated annealing (`method='sa'`).\n",
    "- **Memory Constraints (`max_width`)**: \n",
    "    - If `max_width` is not provided, the optimizer seeks the lowest total cost (FLOPs) without memory limits.\n",
    "    - If `max_width` is provided, the optimizer introduces **index slicing** to ensure that every intermediate tensor fits within the specified memory limit (expressed as $2^{max\\_width}$ elements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419f9fee-7426-40e3-80ec-110214ccc55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer for unconstrained memory\n",
    "opt = Optimizer()\n",
    "\n",
    "# Optimizer with a maximum intermediate tensor width of 2 (i.e., max 2^2 = 4 elements)\n",
    "opt_fw = Optimizer(max_width=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c092943-de17-4779-b2f7-0215a467172a",
   "metadata": {},
   "source": [
    "## 2. Optimizing `cirq.Circuit` Objects\n",
    "\n",
    "The `Optimizer` natively supports `cirq.Circuit` objects. You can specify initial and final states for the qubits to define the contraction problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e137412-a6cf-49a0-bb85-3a4bb978abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random Cirq circuit\n",
    "circuit = cirq.testing.random_circuit(qubits=8, n_moments=16, op_density=1)\n",
    "qubits = sorted(circuit.all_qubits())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation_optimize",
   "metadata": {},
   "source": [
    "The `optimize` method returns:\n",
    "1. A `TensorNetwork` object representing the circuit.\n",
    "2. A list of `ContractionResults` containing the optimized paths.\n",
    "\n",
    "**State Specification:**\n",
    "- By default, initial and final states are assumed to be $|0\\rangle$.\n",
    "- You can provide a dictionary to specify states per qubit.\n",
    "- Use `None` to leave qubits open (uncontracted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39ebaecc-c0f4-4777-8757-d1e0ed624f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization parameters\n",
    "opt_params = {\n",
    "    \"betas\": (0, 1e5),\n",
    "    \"initial_state\": '+',  # All qubits start in the |+> state\n",
    "    \"final_state\":\n",
    "        None,  # All qubits are left open (resulting in a final state vector)\n",
    "    \"n_steps\": 1_000,\n",
    "    \"n_runs\": 4\n",
    "}\n",
    "\n",
    "# Optimize for infinite memory\n",
    "tn, res = opt.optimize(circuit, **opt_params)\n",
    "\n",
    "# Optimize with finite width constraints\n",
    "tn_fw, res_fw = opt_fw.optimize(circuit, **opt_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results_explanation",
   "metadata": {},
   "source": [
    "### Analyzing Contraction Results\n",
    "\n",
    "The `ContractionResults` object provides detailed performance metrics:\n",
    "- `cost`: Contraction cost in floating-point operations (FLOPs).\n",
    "- `path`: The optimal contraction sequence.\n",
    "- `runtime_s`: Time spent on the optimization process.\n",
    "- `slices`: Indices selected for slicing (applicable to finite width)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55a0bfc9-2682-4b74-812b-e0d84787472b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Infinite Memory | Avg Runtime: 0.0067s\n",
      "# Infinite Memory | log10(FLOP): 4.3\n",
      "# -\n",
      "# Finite Width    | Avg Runtime: 0.0089s\n",
      "# Finite Width    | log10(FLOP): 16\n",
      "# Finite Width    | Sliced indices: 44\n"
     ]
    }
   ],
   "source": [
    "# Sort results by cost (lowest first)\n",
    "res = sorted(res, key=lambda x: x.cost)\n",
    "res_fw = sorted(res_fw, key=lambda x: x.cost)\n",
    "\n",
    "\n",
    "# Helper to calculate average runtime\n",
    "def avg_runtime(r):\n",
    "    return sum(x.runtime_s for x in r) / len(r)\n",
    "\n",
    "\n",
    "print(f\"# Infinite Memory | Avg Runtime: {avg_runtime(res):.2g}s\")\n",
    "print(f\"# Infinite Memory | log10(FLOP): {res[0].cost.log10():.2g}\")\n",
    "print(\"# -\")\n",
    "print(f\"# Finite Width    | Avg Runtime: {avg_runtime(res_fw):.2g}s\")\n",
    "print(f\"# Finite Width    | log10(FLOP): {res_fw[0].cost.log10():.2g}\")\n",
    "print(f\"# Finite Width    | Sliced indices: {len(res_fw[0].slices)}\")\n",
    "\n",
    "# Extract the best paths\n",
    "path = res[0].path\n",
    "path_fw = res_fw[0].path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "execution_explanation",
   "metadata": {},
   "source": [
    "### Executing the Contraction\n",
    "\n",
    "You can use the optimized path with external libraries like `quimb` to perform the actual tensor contraction. \n",
    "\n",
    "**Note on Indices:** \n",
    "Output indices are named `(qubit_name, tag)`, where `tag` is `'i'` for the initial state and `'f'` for the final state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfa0238c-9f24-4bfe-bc7d-3009031effb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contraction verified successfully!\n"
     ]
    }
   ],
   "source": [
    "# 1. Calculate the exact state vector using Cirq's simulator for verification\n",
    "initial_state_vec = np.ones(2**len(qubits)) / np.sqrt(2**len(qubits))\n",
    "exact_final_state = cirq.Simulator().simulate(\n",
    "    circuit, initial_state=initial_state_vec,\n",
    "    qubit_order=qubits).state_vector()\n",
    "\n",
    "# 2. Perform tensor network contraction using the optimized path\n",
    "qt_tn = qt.TensorNetwork(map(qt.Tensor, tn.arrays, tn.ts_inds))\n",
    "final_state = qt_tn.contract(optimize=path, output_inds=tn.output_inds)\n",
    "\n",
    "# 3. Post-process the result to match the Cirq state vector format\n",
    "# Re-index: (Qubit, 'f') -> Qubit\n",
    "final_state.reindex({ind: ind[0] for ind in final_state.inds}, inplace=True)\n",
    "\n",
    "# Transpose indices to match the qubit order\n",
    "final_state.transpose(*qubits, inplace=True)\n",
    "\n",
    "# 4. Validate results\n",
    "np.testing.assert_allclose(final_state.data.ravel(),\n",
    "                           exact_final_state,\n",
    "                           atol=1e-5)\n",
    "print(\"Contraction verified successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sampling_intro",
   "metadata": {},
   "source": [
    "## 3. Quantum Circuit Sampling\n",
    "\n",
    "`tnco` implements the algorithm by Bravyi-Gosset-Liu for sampling bitstrings without explicitly computing full marginals.\n",
    "\n",
    "Reference: *\"How to Simulate Quantum Measurement without Computing Marginals\"*, Phys. Rev. Lett. 128, 220503 (2022)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3bec84e-7796-4130-bfc0-c9cac0faeaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Bitstrings:\n",
      "00011010 (12/100 hits)\n",
      "11000000 (10/100 hits)\n",
      "00111010 (9/100 hits)\n",
      "11001100 (7/100 hits)\n",
      "00010010 (7/100 hits)\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Initialize the sampler\n",
    "sampler = Sampler()\n",
    "\n",
    "# Sample random bitstrings from the circuit\n",
    "bitstrings, qubit_order = sampler.sample(circuit,\n",
    "                                         n_samples=100,\n",
    "                                         betas=(0, 1e3),\n",
    "                                         n_steps=100,\n",
    "                                         normalize=False,\n",
    "                                         n_runs=2)\n",
    "print(\"Sampled Bitstrings:\")\n",
    "for bitstring, n_hits in mit.take(5, bitstrings.items()):\n",
    "    print(bitstring, \"({}/100 hits)\".format(n_hits))\n",
    "if len(bitstrings) > 5:\n",
    "    print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate_state_explanation",
   "metadata": {},
   "source": [
    "### Reusing Optimized Intermediate States\n",
    "\n",
    "Optimizing partial tensor networks for sampling can be computationally expensive. `tnco` allows you to generate and save an **optimized intermediate state**, which can be reused for multiple sampling runs without re-optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d60f19f9-43ff-4ede-8dd2-1a42524c19d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reused state sampling completed.\n"
     ]
    }
   ],
   "source": [
    "# 1. Generate the optimized intermediate state\n",
    "state = sampler.sample(circuit,\n",
    "                       return_intermediate_state_only=True,\n",
    "                       betas=(0, 1e3),\n",
    "                       n_steps=100,\n",
    "                       n_runs=2)\n",
    "\n",
    "# 2. The state is pickle-compatible, making it easy to store or distribute\n",
    "pickled_state = pickle.dumps(state)\n",
    "\n",
    "# 3. Reuse the state for sampling\n",
    "bitstrings, qubit_order = sampler.sample(pickle.loads(pickled_state),\n",
    "                                         n_samples=100)\n",
    "print(\"Reused state sampling completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c699cf2-8f31-4d37-a157-2f8db9fe6492",
   "metadata": {},
   "source": [
    "## 4. Optimizing `qiskit.QuantumCircuit` Objects\n",
    "\n",
    "The optimizer provides a consistent interface for Qiskit circuits as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76e2e4c1-99a3-42fc-aa65-abafdee139dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qiskit Optimization log10(FLOP): 4.9\n"
     ]
    }
   ],
   "source": [
    "# Generate a random Qiskit circuit\n",
    "qiskit_circuit = qiskit.QuantumCircuit(8)\n",
    "qiskit_circuit = qiskit_circuit.compose(qiskit_random_circuit(8, 16))\n",
    "\n",
    "# Optimize the Qiskit circuit\n",
    "tn_qiskit, res_qiskit = opt.optimize(qiskit_circuit, **opt_params)\n",
    "best_flops = sorted(res_qiskit, key=lambda x: x.cost)[0].cost\n",
    "print(f\"Qiskit Optimization log10(FLOP): {best_flops.log10():.2g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4856c43c-81b2-4614-863d-64b769108ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Bitstrings:\n",
      "11000000 (13/100 hits)\n",
      "11001100 (10/100 hits)\n",
      "11000100 (9/100 hits)\n",
      "00011010 (9/100 hits)\n",
      "11100000 (9/100 hits)\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Sample random bitstrings from the circuit\n",
    "bitstrings, qubit_order = sampler.sample(circuit,\n",
    "                                         n_samples=100,\n",
    "                                         betas=(0, 1e3),\n",
    "                                         n_steps=100,\n",
    "                                         normalize=False,\n",
    "                                         n_runs=2)\n",
    "print(\"Sampled Bitstrings:\")\n",
    "for bitstring, n_hits in mit.take(5, bitstrings.items()):\n",
    "    print(bitstring, \"({}/100 hits)\".format(n_hits))\n",
    "if len(bitstrings) > 5:\n",
    "    print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc31ee2-830e-4dfe-8f8b-fc9cdf3e2d8d",
   "metadata": {},
   "source": [
    "## 5. Optimizing Lists of Gates\n",
    "\n",
    "Alternatively, you can provide a raw list of unitary matrices and their target qubits using tuples: `(matrix, qubits)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c688e8a4-21ab-44db-ad03-2527e474ba03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gate list optimization log10(FLOP): 4.3\n"
     ]
    }
   ],
   "source": [
    "# Convert Cirq operations to a list of (unitary, qubits) tuples\n",
    "gate_list = [(cirq.unitary(op), op.qubits) for op in circuit.all_operations()]\n",
    "\n",
    "# Optimize the gate list\n",
    "tn_gates, res_gates = opt.optimize(gate_list, **opt_params)\n",
    "best_gate_res = sorted(res_gates, key=lambda x: x.cost)[0]\n",
    "print(f\"Gate list optimization log10(FLOP): {best_gate_res.cost.log10():.2g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8a1bd8-c983-48c1-b813-a7db10a49dd7",
   "metadata": {},
   "source": [
    "## 6. Optimizing Arbitrary Tensor Networks\n",
    "\n",
    "Beyond circuits, you can optimize arbitrary tensor networks by using the `tnco.app.TensorNetwork` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49e50711-1424-4854-91d2-d8d083c48166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arbitrary TN Optimization log10(FLOP): 6.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/google/home/smandra/projects/github/tnco/tnco/app/app.py:328: UserWarning: Cannot decompose hyper-indices if not all arrays are provided.\n",
      "  warn(\"Cannot decompose hyper-indices if not \"\n"
     ]
    }
   ],
   "source": [
    "from tnco.testing.utils import generate_random_tensors\n",
    "\n",
    "# Generate a random tensor network metadata\n",
    "ts_inds, output_inds = generate_random_tensors(n_tensors=10,\n",
    "                                               n_inds=20,\n",
    "                                               n_cc=2,\n",
    "                                               k=3,\n",
    "                                               n_output_inds=3)\n",
    "\n",
    "# Assign random dimensions (2 or 3) to indices\n",
    "all_inds = frozenset(mit.flatten(ts_inds))\n",
    "dims = {ind: Random().randint(2, 3) for ind in all_inds}\n",
    "\n",
    "# Create the TensorNetwork object\n",
    "tn_arbitrary = TensorNetwork([\n",
    "    Tensor(inds, [dims[i]\n",
    "                  for i in inds], tags={'id': j})\n",
    "    for j, inds in enumerate(ts_inds)\n",
    "],\n",
    "                             output_inds=output_inds)\n",
    "\n",
    "# Optimize with fusion (fuse=10 pre-contracts small tensor groups)\n",
    "new_tn, res_arb = opt.optimize(tn_arbitrary,\n",
    "                               fuse=10,\n",
    "                               betas=(0, 1e5),\n",
    "                               n_steps=1_000,\n",
    "                               n_runs=4)\n",
    "print(f\"Arbitrary TN Optimization log10(FLOP): {res_arb[0].cost.log10():.2g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary_execution",
   "metadata": {},
   "source": [
    "### Contracting the Arbitrary Network\n",
    "\n",
    "To execute the contraction, we account for any pre-fused tensors using `tn_utils.contract`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22c37c99-898c-4be8-b000-457fb7aa2610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arbitrary TN contraction completed.\n"
     ]
    }
   ],
   "source": [
    "# Generate random data arrays for the tensors\n",
    "arrays = [np.random.normal(size=t.dims) for t in tn_arbitrary.tensors]\n",
    "\n",
    "# Account for 'fuse' by pre-contracting tensors accordingly\n",
    "fused_inds, fused_output, fused_arrays = tn_utils.contract(\n",
    "    new_tn.tags['fuse_path'],\n",
    "    ts_inds=tn_arbitrary.ts_inds,\n",
    "    output_inds=tn_arbitrary.output_inds,\n",
    "    dims=tn_arbitrary.dims,\n",
    "    arrays=arrays)\n",
    "\n",
    "# Perform final contraction using the best path\n",
    "best_arb_path = sorted(res_arb, key=lambda x: x.cost)[0].path\n",
    "final_result = qt.TensorNetwork(map(qt.Tensor, fused_arrays,\n",
    "                                    new_tn.ts_inds)).contract(\n",
    "                                        optimize=best_arb_path,\n",
    "                                        output_inds=new_tn.output_inds)\n",
    "print(\"Arbitrary TN contraction completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inds_map_explanation",
   "metadata": {},
   "source": [
    "## 7. Advanced: Using Index Maps\n",
    "\n",
    "The optimizer can also accept an **Index Map**, a low-level format where each tuple represents an index, its dimension, and the IDs of connected tensors.\n",
    "\n",
    "**Format:** `(dimension, tensor_id_1, tensor_id_2, ..., '*')` \n",
    "- The `*` token designates an output index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "373ed2b8-335c-45fd-81f3-463d3577382c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Map Optimization log10(FLOP): 6.4\n"
     ]
    }
   ],
   "source": [
    "# Construct an Index Map from the previous network\n",
    "inds_map = {ind: [dims[ind]] for ind in dims}\n",
    "for idx, tensor in enumerate(tn_arbitrary.tensors):\n",
    "    for ind in tensor.inds:\n",
    "        inds_map[ind].append(idx)\n",
    "\n",
    "# Mark outputs\n",
    "for ind in tn_arbitrary.output_inds:\n",
    "    inds_map[ind].append('*')\n",
    "\n",
    "# Optimize using raw map values\n",
    "tn_map, res_map = opt.optimize(inds_map.values(),\n",
    "                               betas=(0, 1e5),\n",
    "                               n_steps=1_000,\n",
    "                               output_index_token='*',\n",
    "                               n_runs=4)\n",
    "print(f\"Index Map Optimization log10(FLOP): {res_map[0].cost.log10():.2g}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
